1.) Kalman Filter - https://medium.com/dataman-in-ai/kalman-filter-explained-4d65b47916bf
2.) Supervised Learning
    a.) XGBoost
    b.) Random Forest
    c.) Decision Tree
    d.) KNN
5.) Keras
    CNN
    RNN
    
6.) Unsupervised Learning
    a.) KMeans
    b.) Autoencoder : denoise images (e.g. numbers) https://www.youtube.com/watch?v=lEfrr0Yr684&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=15
7.) Finish distributions

8.) Sections for
    Rule Extraction (e.g. Recommendations)
    Feature Selection :
        Variance Thresholding : https://towardsdatascience.com/how-to-use-variance-thresholding-for-robust-feature-selection-a4503f2b5c3f

9.) Automate running of multiple models, something like https://towardsdatascience.com/how-to-run-30-machine-learning-models-with-2-lines-of-code-d0f94a537e52        
10.) Image classification using keras' CIFAR 10 and CIFAR 100 datasets.
11.) Text classificataions using keras' 'IMDB - Sentiment Analysis" and 
    "Reuters - Topic classificataions" datasets
12.) Regression using keras' 'Boston Housing Price" dataset
13.) Keras Pretrained Models (use for "Transfer" learning, "as is", or
        do "fine tuning" where we retrain some layers of the original model)
    Image Classification
        many, including Xception, VGG16, VGG19, and many more
